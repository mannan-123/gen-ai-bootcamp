{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 1: Text Collection and Loading**\n",
    "\n",
    "##### **Objective:** *Collect and load a text dataset from a selected domain into a suitable format for processing.*\n",
    "**Domain:** *Environmental*\n",
    "\n",
    "**Kaggle Dataset:** https://www.kaggle.com/datasets/joseguzman/climate-sentiment-in-twitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Necessary Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "# nltk.download('gutenberg')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading a CSV File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id                 date  retweets                   source  \\\n",
      "0  2184934963  2020-12-22 23:22:20        71          Twitter Web App   \n",
      "1   508658626  2020-12-10 14:30:00        14  Twitter for Advertisers   \n",
      "2  2607105006  2020-12-22 21:28:52         0          Twitter Web App   \n",
      "3    19609660  2020-12-22 21:24:10         0          Twitter Web App   \n",
      "4    19609660  2020-12-21 22:52:09         1          Twitter Web App   \n",
      "\n",
      "                         author  likes  \\\n",
      "0                      GO GREEN     91   \n",
      "1               Elsevier Energy     98   \n",
      "2                  Arwyn Thomas      1   \n",
      "3  Tom Gillispie, EDITOR/WRITER      0   \n",
      "4  Tom Gillispie, EDITOR/WRITER      1   \n",
      "\n",
      "                                                text    twitter_name  \\\n",
      "0  The death of summer Arctic ice our Earth coole...    ECOWARRIORSS   \n",
      "1  Elsevier and the EditorsinChief are pleased to...  ElsevierEnergy   \n",
      "2  From better climate change education to improv...         siwarr5   \n",
      "3  climate change Links to FIXING CLIMATE CHANGE ...    EDITORatWORK   \n",
      "4  climate change The 11TH HOUR FOR THE EARTH cli...    EDITORatWORK   \n",
      "\n",
      "                          location  verified  followers  friends  polarity  \\\n",
      "0                              NaN     False      23415    20439 -0.054365   \n",
      "1                  Oxford, England     False       6615      508  0.387500   \n",
      "2                       Carmarthen     False         22      133  0.261905   \n",
      "3  Rural Hall, North Carolina, USA     False       4191     3708  0.000000   \n",
      "4  Rural Hall, North Carolina, USA     False       4191     3708  0.000000   \n",
      "\n",
      "   subjectivity  \n",
      "0      0.426984  \n",
      "1      0.633333  \n",
      "2      0.345238  \n",
      "3      0.000000  \n",
      "4      0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV data into DataFrames\n",
    "df_climate_change = pd.read_csv(\"Climate_twitter.csv\")\n",
    "\n",
    "# Print the first five rows of the DataFrame\n",
    "print(df_climate_change.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part 2: Text Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tokenization: Split the text into words and sentences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  The death of summer Arctic ice our Earth coole...   \n",
      "1  Elsevier and the EditorsinChief are pleased to...   \n",
      "2  From better climate change education to improv...   \n",
      "3  climate change Links to FIXING CLIMATE CHANGE ...   \n",
      "4  climate change The 11TH HOUR FOR THE EARTH cli...   \n",
      "\n",
      "                                           sentences  \\\n",
      "0  [The death of summer Arctic ice our Earth cool...   \n",
      "1  [Elsevier and the EditorsinChief are pleased t...   \n",
      "2  [From better climate change education to impro...   \n",
      "3  [climate change Links to FIXING CLIMATE CHANGE...   \n",
      "4  [climate change The 11TH HOUR FOR THE EARTH cl...   \n",
      "\n",
      "                                               words  \n",
      "0  [The, death, of, summer, Arctic, ice, our, Ear...  \n",
      "1  [Elsevier, and, the, EditorsinChief, are, plea...  \n",
      "2  [From, better, climate, change, education, to,...  \n",
      "3  [climate, change, Links, to, FIXING, CLIMATE, ...  \n",
      "4  [climate, change, The, 11TH, HOUR, FOR, THE, E...  \n"
     ]
    }
   ],
   "source": [
    "# Extract the column with the text data\n",
    "texts = df_climate_change['text']\n",
    "\n",
    "# Function to tokenize sentences\n",
    "def tokenize_sentences(text):\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "# Function to tokenize words\n",
    "def tokenize_words(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "# Apply the tokenization functions to the text column\n",
    "df_climate_change['sentences'] = texts.apply(tokenize_sentences)\n",
    "df_climate_change['words'] = texts.apply(tokenize_words)\n",
    "\n",
    "# Display the DataFrame with the new tokenized columns\n",
    "print(df_climate_change[['text', 'sentences', 'words']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Stemming: Reduce words to their root form.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  The death of summer Arctic ice our Earth coole...   \n",
      "1  Elsevier and the EditorsinChief are pleased to...   \n",
      "2  From better climate change education to improv...   \n",
      "3  climate change Links to FIXING CLIMATE CHANGE ...   \n",
      "4  climate change The 11TH HOUR FOR THE EARTH cli...   \n",
      "\n",
      "                                               words  \\\n",
      "0  [The, death, of, summer, Arctic, ice, our, Ear...   \n",
      "1  [Elsevier, and, the, EditorsinChief, are, plea...   \n",
      "2  [From, better, climate, change, education, to,...   \n",
      "3  [climate, change, Links, to, FIXING, CLIMATE, ...   \n",
      "4  [climate, change, The, 11TH, HOUR, FOR, THE, E...   \n",
      "\n",
      "                                       stemmed_words  \n",
      "0  [the, death, of, summer, arctic, ice, our, ear...  \n",
      "1  [elsevi, and, the, editorsinchief, are, pleas,...  \n",
      "2  [from, better, climat, chang, educ, to, improv...  \n",
      "3  [climat, chang, link, to, fix, climat, chang, ...  \n",
      "4  [climat, chang, the, 11th, hour, for, the, ear...  \n"
     ]
    }
   ],
   "source": [
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to stem words\n",
    "def stem_words(words):\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "\n",
    "# Apply the stemming function to the tokenized words column\n",
    "df_climate_change['stemmed_words'] = df_climate_change['words'].apply(stem_words)\n",
    "\n",
    "# Display the DataFrame with the stemmed words column\n",
    "print(df_climate_change[['text', 'words', 'stemmed_words']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lemmatization: Further reduce the stemmed words by considering their context.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  The death of summer Arctic ice our Earth coole...   \n",
      "1  Elsevier and the EditorsinChief are pleased to...   \n",
      "2  From better climate change education to improv...   \n",
      "3  climate change Links to FIXING CLIMATE CHANGE ...   \n",
      "4  climate change The 11TH HOUR FOR THE EARTH cli...   \n",
      "\n",
      "                                               words  \\\n",
      "0  [The, death, of, summer, Arctic, ice, our, Ear...   \n",
      "1  [Elsevier, and, the, EditorsinChief, are, plea...   \n",
      "2  [From, better, climate, change, education, to,...   \n",
      "3  [climate, change, Links, to, FIXING, CLIMATE, ...   \n",
      "4  [climate, change, The, 11TH, HOUR, FOR, THE, E...   \n",
      "\n",
      "                                    lemmatized_words  \n",
      "0  [The, death, of, summer, Arctic, ice, our, Ear...  \n",
      "1  [Elsevier, and, the, EditorsinChief, are, plea...  \n",
      "2  [From, better, climate, change, education, to,...  \n",
      "3  [climate, change, Links, to, FIXING, CLIMATE, ...  \n",
      "4  [climate, change, The, 11TH, HOUR, FOR, THE, E...  \n"
     ]
    }
   ],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize words\n",
    "def lemmatize_words(words):\n",
    "    return [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "# Apply the lemmatization function to the tokenized words column\n",
    "df_climate_change['lemmatized_words'] = df_climate_change['words'].apply(lemmatize_words)\n",
    "\n",
    "# Display the DataFrame with the lemmatized words column\n",
    "print(df_climate_change[['text', 'words', 'lemmatized_words']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Stop Word Removal: Eliminate common words that may not be useful for analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  The death of summer Arctic ice our Earth coole...   \n",
      "1  Elsevier and the EditorsinChief are pleased to...   \n",
      "2  From better climate change education to improv...   \n",
      "3  climate change Links to FIXING CLIMATE CHANGE ...   \n",
      "4  climate change The 11TH HOUR FOR THE EARTH cli...   \n",
      "\n",
      "                                               words  \\\n",
      "0  [The, death, of, summer, Arctic, ice, our, Ear...   \n",
      "1  [Elsevier, and, the, EditorsinChief, are, plea...   \n",
      "2  [From, better, climate, change, education, to,...   \n",
      "3  [climate, change, Links, to, FIXING, CLIMATE, ...   \n",
      "4  [climate, change, The, 11TH, HOUR, FOR, THE, E...   \n",
      "\n",
      "                                      filtered_words  \n",
      "0  [death, summer, Arctic, ice, Earth, cooler, ye...  \n",
      "1  [Elsevier, EditorsinChief, pleased, share, fir...  \n",
      "2  [better, climate, change, education, improved,...  \n",
      "3  [climate, change, Links, FIXING, CLIMATE, CHAN...  \n",
      "4  [climate, change, 11TH, HOUR, EARTH, climatech...  \n"
     ]
    }
   ],
   "source": [
    "# Get the list of stop words from NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stop words\n",
    "def remove_stop_words(words):\n",
    "    return [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "# Apply the stop word removal function to the tokenized words column\n",
    "df_climate_change['filtered_words'] = df_climate_change['words'].apply(remove_stop_words)\n",
    "\n",
    "# Display the DataFrame with the filtered words column\n",
    "print(df_climate_change[['text', 'words', 'filtered_words']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
